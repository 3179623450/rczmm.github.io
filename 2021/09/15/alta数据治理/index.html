<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"rczmm.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="使用 Apache Atlas 进行数据治理数据治理数据治理意义重大，传统的数据治理采用文档的形式进行管理，已经无法满足大数据下的数据治理需要。而适合于Hadoop大数据生态体系的数据治理就非常的重要了。  大数据下的数据治理作为很多企业的一个巨大的难题，能找到的数据的解决方案并不多，但是好在近几年，很多公司已经进行了尝试并开源了出来，本文将详细分析这些数据发现平台，在国外已经有了十几种的实现方案">
<meta property="og:type" content="article">
<meta property="og:title" content="alta数据治理">
<meta property="og:url" content="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/index.html">
<meta property="og:site_name" content="小小世界">
<meta property="og:description" content="使用 Apache Atlas 进行数据治理数据治理数据治理意义重大，传统的数据治理采用文档的形式进行管理，已经无法满足大数据下的数据治理需要。而适合于Hadoop大数据生态体系的数据治理就非常的重要了。  大数据下的数据治理作为很多企业的一个巨大的难题，能找到的数据的解决方案并不多，但是好在近几年，很多公司已经进行了尝试并开源了出来，本文将详细分析这些数据发现平台，在国外已经有了十几种的实现方案">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/image-20210915093419300.png">
<meta property="og:image" content="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/1253350-20180509182903076-1452084256.jpg">
<meta property="og:image" content="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/1253350-20180509182917037-667288476.jpg">
<meta property="article:published_time" content="2021-09-15T01:20:37.000Z">
<meta property="article:modified_time" content="2021-09-26T05:50:10.883Z">
<meta property="article:author" content="rczmm">
<meta property="article:tag" content="hadoop 转载">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/image-20210915093419300.png">

<link rel="canonical" href="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>alta数据治理 | 小小世界</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0472c4b929e1e8b892e4063622965b6c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="小小世界" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">小小世界</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">永远在路上</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="calendar fa-fw"></i>日程表</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="sitemap fa-fw"></i>站点地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="rczmm">
      <meta itemprop="description" content="你看到的不止如此">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小小世界">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          alta数据治理
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-15 09:20:37" itemprop="dateCreated datePublished" datetime="2021-09-15T09:20:37+08:00">2021-09-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/hadoop/" itemprop="url" rel="index"><span itemprop="name">hadoop</span></a>
                </span>
            </span>

          
             <span id="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/" class="leancloud_visitors" data-flag-title="alta数据治理">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
                 <span class="post-meta-item-text">阅读次数：</span>
                 <span class="leancloud-visitors-count"></span>
             </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
              <span>23k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
              <span>21 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="使用-Apache-Atlas-进行数据治理"><a href="#使用-Apache-Atlas-进行数据治理" class="headerlink" title="使用 Apache Atlas 进行数据治理"></a>使用 Apache Atlas 进行数据治理</h1><h2 id="数据治理"><a href="#数据治理" class="headerlink" title="数据治理"></a>数据治理</h2><p>数据治理意义重大，传统的数据治理采用文档的形式进行管理，已经无法满足大数据下的数据治理需要。而适合于Hadoop大数据生态体系的数据治理就非常的重要了。</p>
<blockquote>
<p>大数据下的数据治理作为很多企业的一个巨大的难题，能找到的数据的解决方案并不多，但是好在近几年，很多公司已经进行了尝试并开源了出来，本文将详细分析这些数据发现平台，在国外已经有了十几种的实现方案。<br>数据发现平台可以解决的问题<br>为什么需要一个数据发现平台？<br>在数据治理过程中，经常会遇到这些问题：</p>
<p>数据都存在哪？</p>
<p>该如何使用这些数据？</p>
<p>数据是做什么的？</p>
<p>数据是如何创建的？</p>
<p>数据是如何更新的？</p>
</blockquote>
<p><strong>数据发现平台的目的就是为了解决上面的问题，帮助更好的查找，理解和使用数据。</strong></p>
<blockquote>
<p>Facebook的Nemo就使用了全文检索技术，这样可以快速的搜索到目标数据。</p>
<p>es（搜索引擎）</p>
</blockquote>
<h3 id="各平台对比"><a href="#各平台对比" class="headerlink" title="各平台对比"></a>各平台对比</h3><p><img src="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/image-20210915093419300.png" alt="image-20210915093419300"></p>
<p>开源的有五家：Amundsen Datahub Metacat Marquez Atlas</p>
<p>有文档的有三家：Amundsen Datahub Atlas</p>
<p>搜索功能较强 ：Amundsen</p>
<p>有数据血统功能：Datahub Atlas</p>
<p>考虑到项目的周期，实施性等情况，还是建议大家从Atlas入门，打开数据治理的探索之路。</p>
<h2 id="alta"><a href="#alta" class="headerlink" title="alta"></a>alta</h2><blockquote>
<p>面对海量且持续增加的各式各样的数据对象，你是否有信心知道哪些数据从哪里来以及它如何随时间而变化？采用Hadoop必须考虑数据管理的实际情况，元数据与数据治理成为企业级数据湖的重要部分。</p>
<p>为寻求数据治理的开源解决方案，Hortonworks 公司联合其他厂商与用户于2015年发起数据治理倡议，包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理等方面。Apache Atlas 项目就是这个倡议的结果，社区伙伴持续的为该项目提供新的功能和特性。该项目用于管理共享元数据、数据分级、审计、安全性以及数据保护等方面，努力与Apache Ranger整合，用于数据权限控制策略。</p>
</blockquote>
<p>Atlas 是一个可扩展和可扩展的核心基础治理服务集 - 使企业能够有效地和高效地满足 Hadoop 中的合规性要求，并允许与整个企业数据生态系统的集成。</p>
<p><img src="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/1253350-20180509182903076-1452084256.jpg" alt="alta数据治理"></p>
<p>Atlas 的组件可以分为以下主要类别：</p>
<h2 id="Core"><a href="#Core" class="headerlink" title="Core"></a>Core</h2><p>此类别包含实现 Atlas 功能核心的组件，包括：</p>
<p>Type System：Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 “类型” 的定义组成。”类型” 的 实例被称为 “实体” 表示被管理的实际元数据对象。类型系统是一个组件，允许用户定义和管理类型和实体。由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。要在 Atlas 中存储新类型的元数据，需要了解类型系统组件的概念。</p>
<p>需要注意的一个关键点是，Atlas 中建模的通用性质允许数据管理员和集成者定义技术元数据和业务元数据。也可以使用 Atlas 的特征来定义两者之间的丰富关系。</p>
<p>Ingest / Export：Ingest 组件允许将元数据添加到 Atlas。类似地，Export 组件暴露由 Atlas 检测到的元数据更改，以作为事件引发，消费者可以使用这些更改事件来实时响应元数据更改。</p>
<p>Graph Engine ：在内部，Atlas 通过使用图形模型管理元数据对象。以实现元数据对象之间的巨大灵活性和丰富的关系。图形引擎是负责在类型系统的类型和实体之间进行转换的组件，以及基础图形模型。除了管理图形对象之外，图形引擎还为元数据对象创建适当的索引，以便有效地搜索它们。</p>
<p>Titan：目前，Atlas 使用 Titan 图数据库来存储元数据对象。 Titan 使用两个存储：默认情况下元数据存储配置为 HBase ，索引存储配置为 Solr。也可以通过构建相应的配置文件将元数据存储作为 BerkeleyDB 和 Index 存储使用为 ElasticSearch。元数据存储用于存储元数据对象本身，并且索引存储用于存储元数据属性的索引，其允许高效搜索。</p>
<h2 id="Integration"><a href="#Integration" class="headerlink" title="Integration"></a>Integration</h2><p>用户可以使用两种方法管理 Atlas 中的元数据：</p>
<p>API：Atlas 的所有功能通过 REST API 提供给最终用户，允许创建，更新和删除类型和实体。它也是查询和发现通过 Atlas 管理的类型和实体的主要方法。</p>
<p>Messaging：除了 API 之外，用户还可以选择使用基于 Kafka 的消息接口与 Atlas 集成。这对于将元数据对象传输到 Atlas 以及从 Atlas 使用可以构建应用程序的元数据更改事件都非常有用。如果希望使用与 Atlas 更松散耦合的集成，这可以允许更好的可扩展性，可靠性等，消息传递接口是特别有用的。Atlas 使用 Apache Kafka 作为通知服务器用于钩子和元数据通知事件的下游消费者之间的通信。事件由钩子和 Atlas 写到不同的 Kafka 主题。</p>
<h3 id="元数据源"><a href="#元数据源" class="headerlink" title="元数据源"></a>元数据源</h3><p>Atlas 支持与许多元数据源的集成。将来还会添加更多集成。目前，Atlas 支持从以下来源获取和管理元数据：</p>
<p><a target="_blank" rel="noopener" href="http://atlas.apache.org/StormAtlasHook.html">HiveSqoopFalconStorm</a></p>
<p>与其它元数据源集成意味着两件事：有一些元数据模型，Atlas 定义本机来表示这些组件的对象。 Atlas 提供了从这些组件中通过实时或批处理模式获取元数据对象的组件。</p>
<h2 id="Apps"><a href="#Apps" class="headerlink" title="Apps"></a>Apps</h2><p>由 Atlas 管理的元数据各种应用程序使用，满足许多治理用例。</p>
<p>Atlas Admin UI：该组件是一个基于 Web 的应用程序，允许数据管理员和科学家发现和注释元数据。这里最重要的是搜索界面和 SQL 样的查询语言，可以用来查询由 Atlas 管理的元数据类型和对象。管理 UI 使用 Atlas 的 REST API 来构建其功能。</p>
<p>Tag Based Policies：Apache Ranger 是针对 Hadoop 生态系统的高级安全管理解决方案，与各种 Hadoop 组件具有广泛的集成。通过与 Atlas 集成，Ranger 允许安全管理员定义元数据驱动的安全策略，以实现有效的治理。 Ranger 是由 Atlas 通知的元数据更改事件的消费者。</p>
<p>Business Taxonomy：从元数据源获取到 Atlas 的元数据对象主要是一种技术形式的元数据。为了增强可发现性和治理能力，Atlas 提供了一个业务分类界面，允许用户首先定义一组代表其业务域的业务术语，并将其与 Atlas 管理的元数据实体相关联。业务分类法是一种 Web 应用程序，目前是 Atlas Admin UI 的一部分，并且使用 REST API 与 Atlas 集成。</p>
<h2 id="Type-System"><a href="#Type-System" class="headerlink" title="Type System"></a>Type System</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 “类型” 的定义组成。被称为 “实体” 的 “类型” 实例表示被管理的实际元数据对象。类型系统是一个组件，允许用户定义和管理类型和实体。由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。要在Atlas中存储新类型的元数据，需要了解类型系统组件的概念。</p>
<h3 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h3><p>Atlas中的 “类型” 定义了如何存储和访问特定类型的元数据对象。类型表示了所定义元数据对象的一个或多个属性集合。具有开发背景的用户可以将 “类型” 理解成面向对象的编程语言的 “类” 定义的或关系数据库的 “表模式”。</p>
<p>与 Atlas 本地定义的类型的示例是 Hive 表。 Hive 表用这些属性定义：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Name: hive_table</span><br><span class="line"> MetaType: Class</span><br><span class="line"> SuperTypes: DataSet</span><br><span class="line"> Attributes:</span><br><span class="line">     name: String (name of the table)</span><br><span class="line">     db: Database object of type hive_db</span><br><span class="line">     owner: String</span><br><span class="line">     createTime: Date</span><br><span class="line">     lastAccessTime: Date</span><br><span class="line">     comment: String</span><br><span class="line">     retention: int</span><br><span class="line">     sd: Storage Description object of type hive_storagedesc</span><br><span class="line">     partitionKeys: Array of objects of type hive_column</span><br><span class="line">     aliases: Array of strings</span><br><span class="line">     columns: Array of objects of type hive_column</span><br><span class="line">     parameters: Map of String keys to String values</span><br><span class="line">     viewOriginalText: String</span><br><span class="line">     viewExpandedText: String</span><br><span class="line">     tableType: String</span><br><span class="line">     temporary: Boolean</span><br></pre></td></tr></table></figure>

<p>从上面的例子可以注意到以下几点：</p>
<ul>
<li>Atlas中的类型由 “name” 唯一标识，</li>
<li>类型具有元类型。元类型表示 Atlas 中此模型的类型。 Atlas 有以下几种类型：<ul>
<li>基本元类型： Int，String，Boolean等。</li>
<li>枚举元类型</li>
<li>集合元类型：例如Array，Map</li>
<li>复合元类型：Class，Struct，Trait</li>
</ul>
</li>
<li>类型可以从称为 “supertype” 的父类型 “extend” - 凭借这一点，它将包含在 “supertype” 中定义的属性。这允许模型在一组相关类型等之间定义公共属性。这再次类似于面向对象语言如何定义类的超类的概念。 Atlas 中的类型也可以从多个超类型扩展。<ul>
<li>在该示例中，每个 hive 表从预定义的超类型（称为 “DataSet”）扩展。稍后将提供关于此预定义类型的更多细节。</li>
</ul>
</li>
<li>具有 “Class”，”Struct” 或 “Trait” 的元类型的类型可以具有属性集合。每个属性都有一个名称（例如 “name”）和一些其他关联的属性。可以使用表达式 type_name.attribute_name 来引用属性。还要注意，属性本身是使用 Atlas 元类型定义的。<ul>
<li>在这个例子中，hive_table.name 是一个字符串，hive_table.aliases 是一个字符串数组，hive_table.db 引用一个类型的实例称为 hive_db 等等。</li>
</ul>
</li>
<li>在属性中键入引用（如hive_table.db）。使用这样的属性，我们可以在 Atlas 中定义的两种类型之间的任意关系，从而构建丰富的模型。注意，也可以收集一个引用列表作为属性类型（例如 hive_table.cols，它表示从 hive_table 到 hive_column 类型的引用列表）</li>
</ul>
<h3 id="Entities"><a href="#Entities" class="headerlink" title="Entities"></a>Entities</h3><p>Atlas中的 “实体” 是类 “类型” 的特定值或实例，因此表示真实世界中的特定元数据对象。 回顾我们的面向对象编程语言的类比，”实例” 是某个 “类” 的 “对象”。</p>
<p>实体的示例将是特定的 Hive 表。 说 “Hive” 在 “默认” 数据库中有一个名为 “customers” 的表。 此表将是类型为 hive_table 的 Atlas 中的 “实体”。 通过作为类类型的实例，它将具有作为 Hive 表 “类型” 的一部分的每个属性的值，例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">id: &quot;9ba387dd-fa76-429c-b791-ffc338d3c91f&quot;</span><br><span class="line"> typeName: “hive_table”</span><br><span class="line"> values:</span><br><span class="line">     name: &quot;customers&quot;</span><br><span class="line">     db: &quot;b42c6cfc-c1e7-42fd-a9e6-890e0adf33bc&quot;</span><br><span class="line">     owner: &quot;admin&quot;</span><br><span class="line">     createTime: &quot;2016-06-20T06:13:28.000Z&quot;</span><br><span class="line">     lastAccessTime: &quot;2016-06-20T06:13:28.000Z&quot;</span><br><span class="line">     comment: null</span><br><span class="line">     retention: 0</span><br><span class="line">     sd: &quot;ff58025f-6854-4195-9f75-3a3058dd8dcf&quot;</span><br><span class="line">     partitionKeys: null</span><br><span class="line">     aliases: null</span><br><span class="line">     columns: [&quot;65e2204f-6a23-4130-934a-9679af6a211f&quot;, &quot;d726de70-faca-46fb-9c99-cf04f6b579a6&quot;, ...]</span><br><span class="line">     parameters: &#123;&quot;transient_lastDdlTime&quot;: &quot;1466403208&quot;&#125;</span><br><span class="line">     viewOriginalText: null</span><br><span class="line">     viewExpandedText: null</span><br><span class="line">     tableType: &quot;MANAGED_TABLE&quot;</span><br><span class="line">     temporary: false</span><br></pre></td></tr></table></figure>

<p>从上面的例子可以注意到以下几点：</p>
<ul>
<li>作为 Class Type 实例的每个实体都由唯一标识符 GUID 标识。此 GUID 由 Atlas 服务器在定义对象时生成，并在实体的整个生命周期内保持不变。在任何时间点，可以使用其 GUID 来访问该特定实体。<ul>
<li>在本示例中，默认数据库中的 “customers” 表由GUID “9ba387dd-fa76-429c-b791-ffc338d3c91f” 唯一标识</li>
</ul>
</li>
<li>实体具有给定类型，并且类型的名称与实体定义一起提供。<ul>
<li>在这个例子中，”customers” 表是一个 “hive_table”。</li>
</ul>
</li>
<li>此实体的值是所有属性名称及其在 hive_table 类型定义中定义的属性的值的映射。</li>
<li>属性值将根据属性的元类型。<ul>
<li>基本元类型：整数，字符串，布尔值。例如。 ‘name’=’customers’，’Temporary’=’false’</li>
<li>集合元类型：包含元类型的值的数组或映射。例如。 parameters = {“transient_lastDdlTime”：”1466403208”}</li>
<li>复合元类型：对于类，值将是与该特定实体具有关系的实体。例如。hive 表 “customers” 存在于称为 “default” 的数据库中。</li>
</ul>
</li>
</ul>
<p>表和数据库之间的关系通过 “db” 属性捕获。因此，”db” 属性的值将是一个唯一标识 hive_db 实体的 GUID，称为 “default”对于实体的这个想法，我们现在可以看到 Class 和 Struct 元类型之间的区别。类和结构体都组成其他类型的属性。但是，类类型的实体具有 Id 属性（具有GUID值）并且可以从其他实体引用（如 hive_db 实体从 hive_table 实体引用）。 Struct 类型的实例没有自己的身份，Struct 类型的值是在实体本身内嵌入的属性的集合。</p>
<h3 id="Attributes"><a href="#Attributes" class="headerlink" title="Attributes"></a>Attributes</h3><p>我们已经看到属性在复合元类型（如 Class 和 Struct）中定义。 但是我们简单地将属性称为具有名称和元类型值。 然而， Atlas 中的属性还有一些属性，定义了与类型系统相关的更多概念。</p>
<p>属性具有以下属性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">name: string,</span><br><span class="line">  dataTypeName: string,</span><br><span class="line">  isComposite: boolean,</span><br><span class="line">  isIndexable: boolean,</span><br><span class="line">  isUnique: boolean,</span><br><span class="line">  multiplicity: enum,</span><br><span class="line">  reverseAttributeName: string</span><br></pre></td></tr></table></figure>

<p>以上属性具有以下含义：</p>
<ul>
<li>name - 属性的名称</li>
<li>dataTypeName - 属性的元类型名称（本机，集合或复合）</li>
<li>isComposite - 是否复合<ul>
<li>此标志指示建模的一个方面。如果一个属性被定义为复合，它意味着它不能有一个生命周期与它所包含的实体无关。这个概念的一个很好的例子是构成 hive 表一部分的一组列。由于列在 hive 表之外没有意义，它们被定义为组合属性。</li>
<li>必须在 Atlas 中创建复合属性及其所包含的实体。即，必须与 hive 表一起创建 hive 列。</li>
</ul>
</li>
<li>isIndexable - 是否索引<ul>
<li>此标志指示此属性是否应该索引，以便可以使用属性值作为谓词来执行查找，并且可以有效地执行查找。</li>
</ul>
</li>
<li>isUnique - 是否唯一<ul>
<li>此标志再次与索引相关。如果指定为唯一，这意味着为 Titan 中的此属性创建一个特殊索引，允许基于等式的查找。</li>
<li>具有此标志的真实值的任何属性都被视为主键，以将此实体与其他实体区分开。因此，应注意确保此属性在现实世界中模拟独特的属性。<ul>
<li>例如，考虑 hive_table 的 name 属性。孤立地，名称不是 hive_table 的唯一属性，因为具有相同名称的表可以存在于多个数据库中。如果 Atlas 在多个集群中存储 hive 表的元数据，即使一对（数据库名称，表名称）也不是唯一的。只有集群位置，数据库名称和表名称可以在物理世界中被视为唯一。</li>
</ul>
</li>
</ul>
</li>
<li>multiplicity - 指示此属性是（必需的／可选的／还是可以是多值）的。如果实体的属性值的定义与类型定义中的多重性声明不匹配，则这将是一个约束违反，并且实体添加将失败。因此，该字段可以用于定义元数据信息上的一些约束。</li>
</ul>
<p>使用上面的内容，让我们扩展下面的 hive 表的属性之一的属性定义。让我们看看称为 “db” 的属性，它表示 hive 表所属的数据库：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">db:</span><br><span class="line">    &quot;dataTypeName&quot;: &quot;hive_db&quot;,</span><br><span class="line">    &quot;isComposite&quot;: false,</span><br><span class="line">    &quot;isIndexable&quot;: true,</span><br><span class="line">    &quot;isUnique&quot;: false,</span><br><span class="line">    &quot;multiplicity&quot;: &quot;required&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;db&quot;,</span><br><span class="line">    &quot;reverseAttributeName&quot;: null</span><br></pre></td></tr></table></figure>

<p>注意多重性的 “multiplicity” = “required” 约束。 如果没有 db 引用，则不能发送表实体。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">columns:</span><br><span class="line">    &quot;dataTypeName&quot;: &quot;array&lt;hive_column&gt;&quot;,</span><br><span class="line">    &quot;isComposite&quot;: true,</span><br><span class="line">    &quot;isIndexable&quot;: true,</span><br><span class="line">    “isUnique&quot;: false,</span><br><span class="line">    &quot;multiplicity&quot;: &quot;optional&quot;,</span><br><span class="line">    &quot;name&quot;: &quot;columns&quot;,</span><br><span class="line">    &quot;reverseAttributeName&quot;: null</span><br></pre></td></tr></table></figure>

<p>请注意列的 “isComposite” = true 值。通过这样做，我们指示定义的列实体应该始终绑定到它们定义的表实体。</p>
<p>从这个描述和示例中，您将能够意识到属性定义可以用于影响 Atlas 系统要执行的特定建模行为（约束，索引等）。</p>
<h3 id="系统特定类型及其意义"><a href="#系统特定类型及其意义" class="headerlink" title="系统特定类型及其意义"></a>系统特定类型及其意义</h3><p>Atlas 提供了一些预定义的系统类型。我们在前面的章节中看到了一个例子（DataSet）。在本节中，我们将看到所有这些类型并了解它们的意义。</p>
<p>Referenceable：此类型表示可使用名为 qualifiedName 的唯一属性搜索的所有实体。</p>
<p>Asset：此类型包含名称，说明和所有者等属性。名称是必需属性（multiplicity = required），其他是可选的。可引用和资源的目的是为定型器提供在定义和查询其自身类型的实体时强制一致性的方法。拥有这些固定的属性集允许应用程序和用户界面基于约定基于默认情况下他们可以期望的属性的假设。</p>
<p>Infrastructure：此类型扩展了可引用和资产，通常可用于基础设施元数据对象（如群集，主机等）的常用超类型。</p>
<p>DataSet：此类型扩展了可引用和资产。在概念上，它可以用于表示存储数据的类型。在 Atlas 中，hive表，Sqoop RDBMS表等都是从 DataSet 扩展的类型。扩展 DataSet 的类型可以期望具有模式，它们将具有定义该数据集的属性的属性。例如， hive_table 中的 columns 属性。另外，扩展 DataSet 的实体类型的实体参与数据转换，这种转换可以由 Atlas 通过 lineage（或 provenance）生成图形。</p>
<p>Process：此类型扩展了可引用和资产。在概念上，它可以用于表示任何数据变换操作。例如，将原始数据的 hive 表转换为存储某个聚合的另一个 hive 表的 ETL 过程可以是扩展过程类型的特定类型。流程类型有两个特定的属性，输入和输出。输入和输出都是 DataSet 实体的数组。因此，Process 类型的实例可以使用这些输入和输出来捕获 DataSet 的 lineage 如何演变。</p>
<h2 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h2><p>Atlas 支持以下 2 种方式搜索元数据:</p>
<ul>
<li>Search using DSL</li>
<li>Full-text search</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://atlas.apache.org/Bridge-Hive.html">Hive Atlas Bridge</a></p>
<h3 id="Hive-Model"><a href="#Hive-Model" class="headerlink" title="Hive Model"></a>Hive Model</h3><p>默认 hive 建模在 org.apache.atlas.hive.model.HiveDataModelGenerator 中可用。 它定义以下类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive_db(ClassType) - super types [Referenceable] - attributes [name, clusterName, description, locationUri, parameters, ownerName, ownerType]</span><br><span class="line">hive_storagedesc(ClassType) - super types [Referenceable] - attributes [cols, location, inputFormat, outputFormat, compressed, numBuckets, serdeInfo, bucketCols, sortCols, parameters, storedAsSubDirectories]</span><br><span class="line">hive_column(ClassType) - super types [Referenceable] - attributes [name, type, comment, table]</span><br><span class="line">hive_table(ClassType) - super types [DataSet] - attributes [name, db, owner, createTime, lastAccessTime, comment, retention, sd, partitionKeys, columns, aliases, parameters, viewOriginalText, viewExpandedText, tableType, temporary]</span><br><span class="line">hive_process(ClassType) - super types [Process] - attributes [name, startTime, endTime, userName, operationType, queryText, queryPlan, queryId]</span><br><span class="line">hive_principal_type(EnumType) - values [USER, ROLE, GROUP]</span><br><span class="line">hive_order(StructType) - attributes [col, order]</span><br><span class="line">hive_serde(StructType) - attributes [name, serializationLib, parameters]</span><br></pre></td></tr></table></figure>

<p>使用唯一的限定名称创建和去重复实体。它们提供命名空间，也可以用于 query／lineage。请注意，dbName，tableName 和 columnName 应为小写。 clusterName 解释如下。</p>
<ul>
<li>hive_db - attribute qualifiedName - <dbName>@<clusterName></clusterName></dbName></li>
<li>hive_table - attribute qualifiedName - <dbName>.<tableName>@<clusterName></clusterName></tableName></dbName></li>
<li>hive_column - attribute qualifiedName - <dbName>.<tableName>.<columnName>@<clusterName></clusterName></columnName></tableName></dbName></li>
<li>hive_process - attribute name - <queryString> - 小写的修剪查询字符串</queryString></li>
</ul>
<h3 id="导入-Hive-Metadata"><a href="#导入-Hive-Metadata" class="headerlink" title="导入 Hive Metadata"></a>导入 Hive Metadata</h3><p>org.apache.atlas.hive.bridge.HiveMetaStoreBridge 使用 org.apache.atlas.hive.model.HiveDataModelGenerator 中定义的模型将 Hive 元数据导入 Atlas。 import-hive.sh 命令可以用来方便这一点。脚本需要 Hadoop 和 Hive 类路径 jar。 对于 Hadoop jar，请确保环境变量 HADOOP_CLASSPATH 已设置。另一种方法是将 HADOOP_HOME 设置为指向 Hadoop 安装的根目录同样，对于 Hive jar，将 HIVE_HOME 设置为 Hive 安装的根目录将环境变量 HIVE_CONF_DIR 设置为 Hive 配置目录复制 ${atlas-conf}/atlas-application.properties 到 hive conf 目录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Usage: &lt;atlas package&gt;/hook-bin/import-hive.sh</span><br></pre></td></tr></table></figure>

<p>日志位于 ${atlas package}/logs/import-hive.log</p>
<p>如果要在 kerberized 集群中导入元数据，则需要运行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;atlas package&gt;/hook-bin/import-hive.sh -Dsun.security.jgss.debug=true -Djavax.security.auth.useSubjectCredsOnly=false -Djava.security.krb5.conf=[krb5.conf location] -Djava.security.auth.login.config=[jaas.conf location]</span><br></pre></td></tr></table></figure>

<ul>
<li>krb5.conf is typically found at /etc/krb5.conf</li>
<li>for details about jaas.conf and a suggested location see the <a target="_blank" rel="noopener" href="http://atlas.apache.org/Security.html">atlas security documentation</a></li>
</ul>
<h3 id="Hive-Hook"><a href="#Hive-Hook" class="headerlink" title="Hive Hook"></a>Hive Hook</h3><p>Hive 在使用 hive hook 的 hive 命令执行上支持侦听器。 这用于在 Atlas 中使用 org.apache.atlas.hive.model.HiveDataModelGenerator 中定义的模型添加/更新/删除实体。 hive hook 将请求提交给线程池执行器，以避免阻塞命令执行。 线程将实体作为消息提交给通知服务器，并且服务器读取这些消息并注册实体。 按照 hive 设置中的这些说明为 Atlas 添加 hive hook ：</p>
<ul>
<li>Set-up atlas hook in hive-site.xml of your hive configuration:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.exec.post.hooks&lt;/name&gt;</span><br><span class="line">&lt;value&gt;org.apache.atlas.hive.hook.HiveHook&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;atlas.cluster.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;primary&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<ul>
<li>Add ‘export HIVE_AUX_JARS_PATH=<atlas package>/hook/hive’ in hive-env.sh of your hive configuration</atlas></li>
<li>Copy <atlas-conf>/atlas-application.properties to the hive conf directory.</atlas-conf></li>
</ul>
<p>在<atlas-conf> /atlas-application.properties中的以下属性控制线程池和通知详细信息：</atlas-conf></p>
<ul>
<li>atlas.hook.hive.synchronous - boolean，true来同步运行钩子。 默认false。 建议设置为false，以避免 hive 查询完成中的延迟。</li>
<li>atlas.hook.hive.numRetries - 通知失败的重试次数。 默认值 3</li>
<li>atlas.hook.hive.minThreads - 核心线程数。 默认值 5</li>
<li>atlas.hook.hive.maxThreads - 最大线程数。 默认值 5</li>
<li>atlas.hook.hive.keepAliveTime - 保持活动时间以毫秒为单位。 默认 10</li>
<li>atlas.hook.hive.queueSize - 线程池的队列大小。 默认 10000</li>
</ul>
<p>参考 <a target="_blank" rel="noopener" href="http://atlas.apache.org/Configuration.html">Configuration</a> 通知相关配置</p>
<h3 id="Column-Level-Lineage"><a href="#Column-Level-Lineage" class="headerlink" title="Column Level Lineage"></a>Column Level Lineage</h3><p>从 atlas-0.8-incubating 版本开始，在 Atlas 中捕获列 lineage</p>
<h4 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h4><ul>
<li>ColumnLineageProcess 类型是 Process 的子类</li>
<li>这将输出列与一组输入列或输入表相关联</li>
<li>Lineage 还捕获 Dependency 的类型：当前的值是 SIMPLE，EXPRESSION，SCRIPT<ul>
<li>SIMPLE依赖： 意味着输出列具有与输入相同的值</li>
<li>EXPRESSION依赖： 意味着输出列被输入列上的运行时中的一些表达式（例如Hive SQL表达式）转换。</li>
<li>SCRIPT依赖： 表示输出列由用户提供的脚本转换。</li>
</ul>
</li>
<li>在 EXPRESSION 依赖的情况下，表达式属性包含字符串形式的表达式</li>
<li>由于 Process 链接输入和输出 DataSet，我们使 Column 成为 DataSet 的子类</li>
</ul>
<h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p>对于下面的简单 CTAS：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table t2 as select id, name from T1</span><br></pre></td></tr></table></figure>

<p>lineage 为</p>
<p><img src="/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/1253350-20180509182917037-667288476.jpg" alt="img"></p>
<h4 id="Extracting-Lineage-from-Hive-commands"><a href="#Extracting-Lineage-from-Hive-commands" class="headerlink" title="Extracting Lineage from Hive commands"></a>Extracting Lineage from Hive commands</h4><ul>
<li>HiveHook 将 HookContext 中的 LineageInfo 映射到 Column lineage 实例</li>
<li>Hive 中的 LineageInfo 为最终的 FileSinkOperator 提供 Column lineage ，将它们链接到 Hive 查询中的输入列</li>
</ul>
<h4 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h4><p>在将 <a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HIVE-13112">HIVE-13112</a> 的补丁应用于 Hive 源之后，列级别 lineage 与 Hive 版本1.2.1配合使用</p>
<h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><ul>
<li>由于数据库名，表名和列名在 hive 中不区分大小写，因此实体中的对应名称为小写。 因此，任何搜索 API 都应该在查询实体名称时使用小写</li>
<li>以下 hive 操作由 hive hook 当前捕获<ul>
<li>create database</li>
<li>create table/view, create table as select</li>
<li>load, import, export</li>
<li>DMLs (insert)</li>
<li>alter database</li>
<li>alter table (skewed table information, stored as, protection is not supported)</li>
<li>alter view</li>
</ul>
</li>
</ul>
<h2 id="Sqoop-Atlas-Bridge"><a href="#Sqoop-Atlas-Bridge" class="headerlink" title="Sqoop Atlas Bridge"></a>Sqoop Atlas Bridge</h2><h3 id="Sqoop-Model"><a href="#Sqoop-Model" class="headerlink" title="Sqoop Model"></a>Sqoop Model</h3><p>默认的 Sqoop 建模在 org.apache.atlas.sqoop.model.SqoopDataModelGenerator 中可用。 它定义以下类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sqoop_operation_type(EnumType) - values [IMPORT, EXPORT, EVAL]</span><br><span class="line">  sqoop_dbstore_usage(EnumType) - values [TABLE, QUERY, PROCEDURE, OTHER]</span><br><span class="line">  sqoop_process(ClassType) - super types [Process] - attributes [name, operation, dbStore, hiveTable, commandlineOpts, startTime, endTime, userName]</span><br><span class="line">  sqoop_dbdatastore(ClassType) - super types [DataSet] - attributes [name, dbStoreType, storeUse, storeUri, source, description, ownerName]</span><br></pre></td></tr></table></figure>

<p>使用唯一的限定名称创建和去重复实体。 它们提供命名空间，也可以用于查询：sqoop_process - attribute name - sqoop-dbStoreType-storeUri-endTime sqoop_dbdatastore - attribute name - dbStoreType-connectorUrl-source</p>
<h3 id="Sqoop-Hook"><a href="#Sqoop-Hook" class="headerlink" title="Sqoop Hook"></a>Sqoop Hook</h3><p>Sqoop 添加了一个 SqoopJobDataPublisher，在完成导入作业后将数据发布到 Atlas。 现在 sqoopHook 只支持hiveImport。 这用于使用 org.apache.atlas.sqoop.model.SqoopDataModelGenerator 中定义的模型在 Atlas 中添加实体。 按照 sqoop 设置中的以下说明在 ${sqoop-conf}/sqoop-site.xml 中为 Atlas 添加 sqoop 钩子：</p>
<ul>
<li>Sqoop Job publisher class. Currently only one publishing class is supported</li>
</ul>
<p>sqoop.job.data.publish.class org.apache.atlas.sqoop.hook.SqoopHook</p>
<ul>
<li>Atlas cluster name</li>
</ul>
<p>atlas.cluster.name</p>
<ul>
<li>复制 ${atlas-conf}/atlas-application.properties 到 sqoop 的配置文件夹 ${sqoop-conf}/</li>
<li>Link ${atlas-home}/hook/sqoop/*.jar in sqoop libRefer <a target="_blank" rel="noopener" href="http://atlas.apache.org/Configuration.html">Configuration</a> for notification related configurations</li>
</ul>
<h3 id="Limitations-1"><a href="#Limitations-1" class="headerlink" title="Limitations"></a>Limitations</h3><ul>
<li>目前 sqoop hook 只支持 hiveImport 这一种 sqoop 操作</li>
</ul>
<h2 id="Falcon-Atlas-Bridge"><a href="#Falcon-Atlas-Bridge" class="headerlink" title="Falcon Atlas Bridge"></a>Falcon Atlas Bridge</h2><h3 id="Falcon-Model"><a href="#Falcon-Model" class="headerlink" title="Falcon Model"></a>Falcon Model</h3><p>默认的falcon建模在 org.apache.atlas.falcon.model.FalconDataModelGenerator. 它可以定义以下类型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">falcon_cluster(ClassType) - super types [Infrastructure] - attributes [timestamp, colo, owner, tags]</span><br><span class="line">falcon_feed(ClassType) - super types [DataSet] - attributes [timestamp, stored-in, owner, groups, tags]</span><br><span class="line">falcon_feed_creation(ClassType) - super types [Process] - attributes [timestamp, stored-in, owner]</span><br><span class="line">falcon_feed_replication(ClassType) - super types [Process] - attributes [timestamp, owner]</span><br><span class="line">falcon_process(ClassType) - super types [Process] - attributes [timestamp, runs-on, owner, tags, pipelines, workflow-properties]</span><br></pre></td></tr></table></figure>

<p>为 falcon 进程定义的每个集群创建一个 falcon_process 实体。</p>
<p>使用唯一的 qualifiedName 属性创建和去重复实体。 它们提供命名空间，也可以用于查询/沿袭。 唯一的属性是：</p>
<ul>
<li>falcon_process - <process name>@<cluster name></cluster></process></li>
<li>falcon_cluster - <cluster name></cluster></li>
<li>falcon_feed - <feed name>@<cluster name></cluster></feed></li>
<li>falcon_feed_creation - <feed name></feed></li>
<li>falcon_feed_replication - <feed name></feed></li>
</ul>
<h3 id="Falcon-Hook"><a href="#Falcon-Hook" class="headerlink" title="Falcon Hook"></a>Falcon Hook</h3><p>Falcon 支持在 falcon 实体提交上的侦听器。 这用于在 Atlas 中使用 org.apache.atlas.falcon.model.FalconDataModelGenerator 中定义的模型添加实体。 hook 将请求提交给线程池执行器，以避免阻塞命令执行。 线程将实体作为消息提交给通知服务器，并且服务器读取这些消息并注册实体。</p>
<ul>
<li>Add ‘org.apache.atlas.falcon.service.AtlasService’ to application.services in ${falcon-conf}/startup.properties</li>
<li>Link falcon hook jars in falcon classpath - ‘ln -s atlas−home/hook/falcon/∗{falcon-home}/server/webapp/falcon/WEB-INF/lib/‘</li>
<li>In ${falcon_conf}/falcon-env.sh, set an environment variable as follows:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export FALCON_SERVER_OPTS=&quot;&lt;atlas_home&gt;/hook/falcon/*:$FALCON_SERVER_OPTS&quot;</span><br></pre></td></tr></table></figure>

<p>The following properties in ${atlas-conf}/atlas-application.properties control the thread pool and notification details:</p>
<ul>
<li>atlas.hook.falcon.synchronous - boolean, true to run the hook synchronously. default false</li>
<li>atlas.hook.falcon.numRetries - number of retries for notification failure. default 3</li>
<li>atlas.hook.falcon.minThreads - core number of threads. default 5</li>
<li>atlas.hook.falcon.maxThreads - maximum number of threads. default 5</li>
<li>atlas.hook.falcon.keepAliveTime - keep alive time in msecs. default 10</li>
<li>atlas.hook.falcon.queueSize - queue size for the threadpool. default 10000</li>
</ul>
<p>Refer <a target="_blank" rel="noopener" href="http://atlas.apache.org/Configuration.html">Configuration</a> for notification related configurations</p>
<h3 id="Limitations-2"><a href="#Limitations-2" class="headerlink" title="Limitations"></a>Limitations</h3><ul>
<li>在 falcon 集群实体中，使用的集群名称应该跨诸如 hive，falcon，sqoop 等组件是统一的。如果与 ambari 一起使用，则应该使用 ambari 集群名称用于集群实体</li>
</ul>
<h2 id="Storm-Atlas-Bridge"><a href="#Storm-Atlas-Bridge" class="headerlink" title="Storm Atlas Bridge"></a>Storm Atlas Bridge</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Apache Storm 是一个分布式实时计算系统。 Storm 使得容易可靠地处理无界的数据流，为实时处理 Hadoop 对批处理所做的工作。 该过程实质上是节点的 DAG，其被称为 topology。</p>
<p>Apache Atlas 是一个元数据存储库，支持端到端数据沿袭，搜索和关联业务分类。</p>
<p>这种集成的目的是推动操作 topology 元数据以及基础数据源，目标，推导过程和任何可用的业务上下文，以便 Atlas 可以捕获此 topology 的 lineage。</p>
<p>在此过程中有2个部分详述如下：</p>
<ul>
<li>Data model to represent the concepts in Storm</li>
<li>Storm Atlas Hook to update metadata in Atlas</li>
</ul>
<h3 id="Storm-Data-Model"><a href="#Storm-Data-Model" class="headerlink" title="Storm Data Model"></a>Storm Data Model</h3><p>数据模型在 Atlas 中表示为 Types。 它包含 topology 图中各种节点的描述，例如 spouts 和 bolts 以及相应的生产者和消费者类型。</p>
<p>在Atlas中添加以下类型。</p>
<ul>
<li>storm_topology - 表示粗粒度拓扑。storm_topology 来自于 Atlas 过程类型，因此可用于通知 Atlas 关于 lineage。</li>
<li>添加以下数据集 - kafka_topic，jms_topic，hbase_table，hdfs_data_set。 这些都来自Atlas Dataset类型，因此形成谱系图的端点。</li>
<li>storm_spout - 具有输出的数据生产者，通常为Kafka，JMS</li>
<li>storm_bolt - 具有输入和输出的数据使用者，通常为Hive，HBase，HDFS等。</li>
</ul>
<p>Storm Atlas hook自动注册依赖模型，如Hive数据模型，如果它发现这些是不为Atlas服务器所知。</p>
<p>每个类型的数据模型在类定义org.apache.atlas.storm.model.StormDataModel中描述。</p>
<h3 id="Storm-Atlas-Hook"><a href="#Storm-Atlas-Hook" class="headerlink" title="Storm Atlas Hook"></a>Storm Atlas Hook</h3><p>当在 Storm 中成功注册新 topology 时，通知 Atlas。 Storm 在 Storm 客户端提供了一个钩子，backtype.storm.ISubmitterHook，用于提交一个 Storm topology。</p>
<p>Storm Atlas hook 拦截 hook 后执行，并从 topology 中提取元数据，并使用定义的类型更新 Atlas。 Atlas 在org.apache.atlas.storm.hook.StormAtlasHook 中实现了 Storm 客户端 hook 接口。</p>
<h3 id="Limitations-3"><a href="#Limitations-3" class="headerlink" title="Limitations"></a>Limitations</h3><p>以下内容适用于集成的第一个版本。</p>
<ul>
<li>只有新的 topology 提交已注册到 Atlas，任何生命周期变化都不会反映在 Atlas 中。</li>
<li>当为要捕获的元数据提交 Storm topology 时，Atlas 服务器需要在线。</li>
<li>hook 目前不支持捕获自定义 spouts 和 bolts 的 lineage。</li>
</ul>
<h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><p>Storm Atlas Hook 需要在客户端手动安装在 Storm 在：$ATLAS_PACKAGE/hook/storm</p>
<p>Storm Atlas Hook 需要复制到 $STORM_HOME/extlib。 使用 storm 安装路径替换 STORM_HOME。</p>
<p>在将安装了 atlas hook 到 Storm 后重新启动所有守护进程。</p>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><h4 id="Storm-Configuration"><a href="#Storm-Configuration" class="headerlink" title="Storm Configuration"></a>Storm Configuration</h4><p>Storm Atlas Hook 需要在 Storm 客户端 $STORM_HOME/conf/storm.yaml 进行配置:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm.topology.submission.notifier.plugin.class: &quot;org.apache.atlas.storm.hook.StormAtlasHook&quot;</span><br></pre></td></tr></table></figure>

<p>还设置一个 “集群名称”，将用作在 Atlas 中注册的对象的命名空间。 此名称将用于命名 Storm topology，spouts 和 bolts。</p>
<p>其他对象（如 Dataset）应该理想地用生成它们的组件的集群名称来标识。 例如， Hive 表和数据库应该使用在 Hive 中设置的集群名称来标识。 如果 Hive 配置在客户端上提交的 Storm topology jar 中可用，并且在那里定义了集群名称，Storm Atlas hook 将选择此选项。 对于 HBase 数据集，这种情况类似。 如果此配置不可用，将使用在 Storm 配置中设置的集群名称。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atlas.cluster.name: &quot;cluster_name&quot;</span><br></pre></td></tr></table></figure>

<p>在 $STORM_HOME/conf/storm_env.ini 中, 设置以下环境变量:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">STORM_JAR_JVM_OPTS:&quot;-Datlas.conf=$ATLAS_HOME/conf/&quot;</span><br></pre></td></tr></table></figure>

<p>将 ATLAS_HOME 指向 ATLAS 的安装目录.</p>
<p>你也可以通过程序对 Storm 进行如下配置:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Config stormConf = new Config();</span><br><span class="line">  ...</span><br><span class="line">  stormConf.put(Config.STORM_TOPOLOGY_SUBMISSION_NOTIFIER_PLUGIN,</span><br><span class="line">  org.apache.atlas.storm.hook.StormAtlasHook.class.getName());</span><br></pre></td></tr></table></figure>

<h2 id="容错和高可用"><a href="#容错和高可用" class="headerlink" title="容错和高可用"></a>容错和高可用</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Apache Atlas 使用各种系统并与其交互，为数据管理员提供元数据管理和数据 lineage。 通过适当地选择和配置这些依赖关系，可以使用 Atlas 实现高度的服务可用性。 本文档介绍了 Atlas 的高可用性支持状态，包括其功能和当前限制，以及实现此级别高可用性所需的配置。</p>
<h3 id="Atlas-Web-Service"><a href="#Atlas-Web-Service" class="headerlink" title="Atlas Web Service"></a>Atlas Web Service</h3><p>目前，Atlas Web 服务有一个限制，它一次只能有一个活动实例。在早期版本的 Atlas 中，可以配置和保持备份实例。但是，需要手动故障转移才能使此备份实例处于活动状态。</p>
<p>从这个版本开始，Atlas 将支持带有自动故障转移的 主动/被动 配置中的 Atlas Web 服务的多个实例。这意味着用户可以在不同的物理主机上同时部署和启动 Atlas Web 服务的多个实例。其中一个实例将被自动选择为 “活动” 实例来为用户请求提供服务。其他人将自动被视为 “被动”。如果 “活动” 实例由于故意停止或由于意外故障而变得不可用，则其他实例之一将自动选为 “活动” 实例，并开始为用户请求提供服务。</p>
<p>“活动” 实例是能够正确响应用户请求的唯一实例。它可以创建，删除，修改或响应元数据对象上的查询。 “被动” 实例将接受用户请求，但会使用 HTTP 重定向将其重定向到当前已知的 “活动” 实例。具体来说，被动实例本身不会响应对元数据对象的任何查询。但是，所有实例（包括主动和被动）都将响应返回有关该实例的信息的管理请求。</p>
<p>当配置为高可用性模式时，用户可以获得以下操作优势：</p>
<ul>
<li>在维护间隔期间不间断服务：如果需要停用 Atlas Web 服务的活动实例进行维护，则另一个实例将自动变为活动状态并可以为请求提供服务。</li>
<li>在意外故障事件中的不间断服务：如果由于软件或硬件错误，Atlas Web 服务的活动实例失败，另一个实例将自动变为活动状态并可以为请求提供服务。</li>
</ul>
<p>在以下小节中，我们将介绍为 Atlas Web 服务设置高可用性所需的步骤。 我们还描述了如何设计部署和客户端以利用此功能。 最后，我们描述一些底层实现的细节。</p>
<h4 id="Setting-up-the-High-Availability-feature-in-Atlas"><a href="#Setting-up-the-High-Availability-feature-in-Atlas" class="headerlink" title="Setting up the High Availability feature in Atlas"></a>Setting up the High Availability feature in Atlas</h4><p>设置高可用性功能必须满足以下先决条件。</p>
<ul>
<li>确保在一组计算机上安装 Apache Zookeeper（建议至少使用3台服务器进行生产）。</li>
<li>选择 2 个或更多物理机以在其上运行 Atlas Web Service 实例。这些机器定义了我们称为 Atlas 的 “服务器集合”。</li>
</ul>
<p>要在 Atlas 中设置高可用性，必须在 atlas-application.properties 文件中定义一些配置选项。虽然配置项的完整列表在配置页中定义，但本节列出了几个主要选项。</p>
<ul>
<li><p>高可用性是 Atlas 的可选功能。因此，必须通过将配置选项 atlas.server.ha.enabled 设置为 true 来启用。</p>
</li>
<li><p>接下来，定义标识符列表，为您为 Atlas Web Service 实例选择的每个物理机器分配一个标识符。这些标识符可以是简单的字符串，如id1，id2等。它们应该是唯一的，不应包含逗号。</p>
</li>
<li><p>将这些标识符的逗号分隔列表定义为选项 atlas.server.ids 的值。</p>
</li>
<li><p>对于每个物理机，请列出IP地址/主机名和端口作为配置 atlas.server.address.id 的值，其中 id 指的是此物理机的标识符字符串。</p>
<ul>
<li><p>例如，如果您选择了 2 台主机名为 和 的计算机，则可以如下定义配置选项：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">atlas.server.ids=id1,id2</span><br><span class="line">atlas.server.address.id1=host1.company.com:21000</span><br><span class="line">atlas.server.address.id2=host2.company.com:21000</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>定义使用的 Zookeeper 为 Atlas 提供高可用性功能</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atlas.server.ha.zookeeper.connect=zk1.company.com:2181,zk2.company.com:2181,zk3.company.com:2181</span><br></pre></td></tr></table></figure>

<ul>
<li>您可以查看为高可用性功能定义的其他配置选项，并根据需要在 atlas-application.properties 文件中进行设置。</li>
<li>对于生产环境，Atlas 所依赖的组件也必须在高可用性模式下设置。 这将在以下部分中详细描述。 按照这些说明设置和配置它们。</li>
<li>在选定的物理机器上安装 Atlas 软件。</li>
<li>将使用上述步骤创建的 atlas-application.properties 文件复制到所有计算机的配置目录。</li>
<li>启动相关组件。</li>
<li>启动 Atlas Web 服务的每个实例。</li>
</ul>
<p>要验证高可用性是否正常工作，请在安装了 Atlas Web Service 的每个实例上运行以下脚本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ATLAS_HOME/bin/atlas_admin.py -status</span><br></pre></td></tr></table></figure>

<p>此脚本可以打印以下值之一作为响应：</p>
<ul>
<li>ACTIVE：此实例处于活动状态，可以响应用户请求。</li>
<li>PASSIVE：此实例为 PASSIVE。它会将它收到的任何用户请求重定向到当前活动实例。</li>
<li>BECOMING_ACTIVE：如果服务器正在转换为 ACTIVE 实例，则将打印此消息。在此状态下，服务器无法处理任何元数据用户请求。</li>
<li>BECOMING_PASSIVE：如果服务器正在转换为 PASSIVE 实例，则将打印此消息。在此状态下，服务器无法处理任何元数据用户请求。</li>
</ul>
<p>在正常操作情况下，只有其中一个实例应该打印 ACTIVE 值作为对脚本的响应，而其他实例将打印 PASSIVE。</p>
<h4 id="配置客户端以使用高可用性功能"><a href="#配置客户端以使用高可用性功能" class="headerlink" title="配置客户端以使用高可用性功能"></a>配置客户端以使用高可用性功能</h4><p>Atlas Web 服务可以通过两种方式访问：</p>
<ul>
<li>使用 Atlas Web UI：这是一个基于浏览器的客户端，可用于查询存储在Atlas中的元数据。</li>
<li>使用 Atlas REST API：由于 Atlas 公开了一个 RESTful API，因此可以使用任何标准的 REST 客户端，包括其他应用程序中的库。事实上，Atlas 附带了一个名为 AtlasClient 的客户端，可以用作创建 REST 客户端访问的示例。</li>
</ul>
<p>为了利用客户端中的高可用性功能，可以有两个选项。</p>
<h4 id="使用中间代理"><a href="#使用中间代理" class="headerlink" title="使用中间代理"></a>使用中间代理</h4><p>启用高可用性访问 Atlas 的最简单的解决方案是安装和配置一些中间代理，其具有基于状态透明地切换服务的能力。一个这样的代理解决方案是 HAProxy。</p>
<p>下面是一个可以使用的 HAProxy 配置示例。注意，这只是为了说明，而不是作为推荐的生产配置。为此，请参阅 HAProxy文档以获取相应的说明。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">frontend atlas_fe</span><br><span class="line">  bind *:41000</span><br><span class="line">  default_backend atlas_be</span><br><span class="line"></span><br><span class="line">backend atlas_be</span><br><span class="line">  mode http</span><br><span class="line">  option httpchk get /api/atlas/admin/status</span><br><span class="line">  http-check expect string ACTIVE</span><br><span class="line">  balance roundrobin</span><br><span class="line">  server host1_21000 host1:21000 check</span><br><span class="line">  server host2_21000 host2:21000 check backup</span><br><span class="line"></span><br><span class="line">listen atlas</span><br><span class="line">  bind localhost:42000</span><br></pre></td></tr></table></figure>

<p>以上配置绑定 HAProxy 侦听端口 41000 传入客户端连接。然后根据 HTTP 状态检查将连接路由到主机 host1 或 host2 中的任一个。状态检查是使用 REST URL / api / atlas / admin / status 上的 HTTP GET 完成的，只有当 HTTP 响应包含字符串ACTIVE 时，才认为成功。</p>
<h4 id="使用活动实例的自动检测"><a href="#使用活动实例的自动检测" class="headerlink" title="使用活动实例的自动检测"></a>使用活动实例的自动检测</h4><p>如果不想设置和管理单独的代理，则使用高可用性功能的另一个选项是构建能够检测状态和重试操作的客户端应用程序。在这样的设置中，可以使用形成集合的所有 Atlas Web 服务实例的 URL 启动客户端应用程序。然后，客户端应调用其中每一个上的 REST URL / api / atlas / admin / status，以确定哪个是活动实例。来自 Active 实例的响应将具有 {Status：ACTIVE}的形式。此外，当客户端在操作过程中遇到任何异常时，它应该再次确定哪些剩余的URL是活动的并重试该操作。</p>
<p>Atlas 附带的 AtlasClient 类可以用作一个示例客户端库，它实现了使用集合并选择正确的Active服务器实例的逻辑。</p>
<p>Atlas 中的实用程序（如quick_start.py和import-hive.sh）可以配置为使用多个服务器URL运行。当在此模式下启动时，AtlasClient 自动选择并使用当前活动实例。如果在之间设置了代理，则可以在运行 quick_start.py 或 import-hive.sh 时使用其地址。</p>
<h4 id="实现-Atlas-高可用"><a href="#实现-Atlas-高可用" class="headerlink" title="实现 Atlas 高可用"></a>实现 Atlas 高可用</h4><p>Atlas 高可用性工作在主 JIRA <a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/ATLAS-510">ATLAS-510</a> 下进行跟踪。根据其提交的 JIRA 具有关于高可用性功能如何实现的详细信息。在高级别可以调出以下几点：</p>
<ul>
<li>活动实例的自动选择以及到新的活动实例的自动故障转移通过领导者选择算法发生。</li>
<li>对于领导选举，我们使用 Apache Curator 的 Leader Latch Recipe。</li>
<li>Active 实例是唯一一个在后端存储中初始化，修改或读取状态以保持它们一致的实例。</li>
<li>此外，当实例被选为活动时，它会刷新后端存储中的任何缓存信息以获取最新信息。</li>
<li>servlet 过滤器确保只有活动的实例服务用户请求。如果被动实例接收到这些请求，它会自动将它们重定向到当前活动实例。</li>
</ul>
<h4 id="Metadata-Store"><a href="#Metadata-Store" class="headerlink" title="Metadata Store"></a>Metadata Store</h4><p>如上所述，Atlas 使用 Titan 来存储它管理的元数据。默认情况下，Atlas 使用独立的 HBase 实例作为 Titan 的后备存储。为了为元数据存储提供 HA，我们建议将 Atlas 配置为使用分布式 HBase 作为 Titan 的后备存储。这意味着您可以从 HBase 提供的 HA 保证中受益。为了将 Atlas 配置为在 HA 模式下使用 HBase，请执行以下操作：</p>
<ul>
<li>选择在HA模式中设置的现有 HBase 集群以在 Atlas（OR）中配置在 <a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#quickstart_fully_distributed">HA模式</a> 下设置新的 HBase 集群。<ul>
<li>如果为 Atlas 设置 HBase，请按照 <a target="_blank" rel="noopener" href="http://atlas.apache.org/InstallationSteps.html">Installation Steps</a> 中列出的用于设置 HBase 的说明进行操作。</li>
</ul>
</li>
<li>我们建议在使用 Zookeeper 协调的不同物理主机上的集群中使用多个 HBase 主机（至少2个），以提供 HBase的 冗余和高可用性。<ul>
<li>有关在 atlas.properties 中配置的选项的 <a target="_blank" rel="noopener" href="http://atlas.apache.org/Configuration.html">Configuration page</a> ，请参考配置页面，以便使用 HBase 设置 Atlas。</li>
</ul>
</li>
</ul>
<h3 id="Index-Store"><a href="#Index-Store" class="headerlink" title="Index Store"></a>Index Store</h3><p>如上所述，Atlas 通过 Titan 索引元数据以支持全文搜索查询。 为了为索引存储提供 HA，我们建议将 Atlas 配置为使用 Solr作为 Titan 的后备索引存储。 为了将 Atlas 配置为在 HA 模式下使用 Solr，请执行以下操作：</p>
<ul>
<li>在 HA 模式下选择现有的 SolrCloud 群集设置以在 Atlas（OR）中配置设置新的 SolrCloud 群集。<ul>
<li>确保 Solr 在至少 2 个物理主机上启动以实现冗余，并且每个主机运行 Solr 节点。</li>
<li>我们建议将冗余数设置为至少 2。</li>
</ul>
</li>
<li>创建 Atlas 所需的 SolrCloud 集合，如安装步骤中所述</li>
<li>请参阅配置页面以了解在 atlas.properties 中配置的选项，以使用 Solr 设置 Atlas。</li>
</ul>
<h3 id="Notification-Server"><a href="#Notification-Server" class="headerlink" title="Notification Server"></a>Notification Server</h3><p>来自 Hook 的元数据通知事件通过写入到名为 ATLAS_HOOK 的 Kafka topic 发送到 Atlas 。类似地，从 Atlas 到其他集成组件（如Ranger）的事件写入名为 ATLAS_ENTITIES 的 Kafka topic。由于 Kafka 会保留这些消息，即使消费者在发送事件时失败，事件也不会丢失。此外，我们建议 Kafka 也设置容错，以便它具有更高的可用性保证。为了配置 Atlas 在 HA 模式下使用 Kafka，请执行以下操作：</p>
<ul>
<li><p>选择在 HA 模式中设置的现有 Kafka 集群以在 Atlas（OR）中配置设置新的 Kafka 集群。</p>
</li>
<li><p>我们建议在不同物理主机上的群集中有多个 Kafka 代理，它们使用 Zookeeper 协调，以提供 Kafka 的冗余和高可用性。</p>
<ul>
<li>设置至少 2 个物理主机以实现冗余，每个托管一个 Kafka 代理。</li>
</ul>
</li>
<li><p>为 Atlas 使用设置 Kafka 主题：</p>
<ul>
<li>ATLAS 主题的分区数应设置为1（numPartitions）</li>
<li>确定 Kafka 主题的副本数量：将此值设置为至少 2 以进行冗余。</li>
<li>运行以下命令：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$KAFKA_HOME/bin/kafka-topics.sh --create --zookeeper &lt;list of zookeeper host:port entries&gt; --topic ATLAS_HOOK --replication-factor &lt;numReplicas&gt; --partitions 1</span><br><span class="line">$KAFKA_HOME/bin/kafka-topics.sh --create --zookeeper &lt;list of zookeeper host:port entries&gt; --topic ATLAS_ENTITIES --replication-factor &lt;numReplicas&gt; --partitions 1</span><br><span class="line">Here KAFKA_HOME points to the Kafka installation directory.</span><br></pre></td></tr></table></figure>

<ul>
<li>在 atlas-application.properties 中进行如下配置:</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">atlas.notification.embedded=false</span><br><span class="line">atlas.kafka.zookeeper.connect=&lt;comma separated list of servers forming Zookeeper quorum used by Kafka&gt;</span><br><span class="line">atlas.kafka.bootstrap.servers=&lt;comma separated list of Kafka broker endpoints in host:port form&gt; - Give at least 2 for redundancy.</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="Known-Issues"><a href="#Known-Issues" class="headerlink" title="Known Issues"></a>Known Issues</h3><ul>
<li>如果托管 Atlas ‘titan’ HTable 的 HBase region servers 停机，Atlas 将无法在 HBase 恢复联机之前从 HBase 存储或检索元数据。</li>
</ul>

    </div>
 <div>
      
        <div>
    
        <div style="text-align:center;color: #555;font-size:24px;"><-------------文章到这里就结束了！-------------></div>
    
</div>

      
    </div>
    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="rczmm 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="rczmm 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>rczmm
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://rczmm.github.io/2021/09/15/alta%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/" title="alta数据治理">http://rczmm.github.io/2021/09/15/alta数据治理/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/hadoop-%E8%BD%AC%E8%BD%BD/" rel="tag"><i class="fa fa-tag"></i> hadoop 转载</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/12/js%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7/" rel="prev" title="js对象高级">
      <i class="fa fa-chevron-left"></i> js对象高级
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/09/17/numpy%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/" rel="next" title="numpy基础入门">
      numpy基础入门 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>


  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-Apache-Atlas-%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">使用 Apache Atlas 进行数据治理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86"><span class="nav-number">1.1.</span> <span class="nav-text">数据治理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%84%E5%B9%B3%E5%8F%B0%E5%AF%B9%E6%AF%94"><span class="nav-number">1.1.1.</span> <span class="nav-text">各平台对比</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#alta"><span class="nav-number">1.2.</span> <span class="nav-text">alta</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Core"><span class="nav-number">1.3.</span> <span class="nav-text">Core</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Integration"><span class="nav-number">1.4.</span> <span class="nav-text">Integration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE%E6%BA%90"><span class="nav-number">1.4.1.</span> <span class="nav-text">元数据源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Apps"><span class="nav-number">1.5.</span> <span class="nav-text">Apps</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Type-System"><span class="nav-number">1.6.</span> <span class="nav-text">Type System</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Overview"><span class="nav-number">1.6.1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Types"><span class="nav-number">1.6.2.</span> <span class="nav-text">Types</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Entities"><span class="nav-number">1.6.3.</span> <span class="nav-text">Entities</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Attributes"><span class="nav-number">1.6.4.</span> <span class="nav-text">Attributes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B3%BB%E7%BB%9F%E7%89%B9%E5%AE%9A%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%85%B6%E6%84%8F%E4%B9%89"><span class="nav-number">1.6.5.</span> <span class="nav-text">系统特定类型及其意义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Search"><span class="nav-number">1.7.</span> <span class="nav-text">Search</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Model"><span class="nav-number">1.7.1.</span> <span class="nav-text">Hive Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%BC%E5%85%A5-Hive-Metadata"><span class="nav-number">1.7.2.</span> <span class="nav-text">导入 Hive Metadata</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Hook"><span class="nav-number">1.7.3.</span> <span class="nav-text">Hive Hook</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Column-Level-Lineage"><span class="nav-number">1.7.4.</span> <span class="nav-text">Column Level Lineage</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Model"><span class="nav-number">1.7.4.1.</span> <span class="nav-text">Model</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Examples"><span class="nav-number">1.7.4.2.</span> <span class="nav-text">Examples</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Extracting-Lineage-from-Hive-commands"><span class="nav-number">1.7.4.3.</span> <span class="nav-text">Extracting Lineage from Hive commands</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#NOTE"><span class="nav-number">1.7.4.4.</span> <span class="nav-text">NOTE</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Limitations"><span class="nav-number">1.7.5.</span> <span class="nav-text">Limitations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sqoop-Atlas-Bridge"><span class="nav-number">1.8.</span> <span class="nav-text">Sqoop Atlas Bridge</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sqoop-Model"><span class="nav-number">1.8.1.</span> <span class="nav-text">Sqoop Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sqoop-Hook"><span class="nav-number">1.8.2.</span> <span class="nav-text">Sqoop Hook</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Limitations-1"><span class="nav-number">1.8.3.</span> <span class="nav-text">Limitations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Falcon-Atlas-Bridge"><span class="nav-number">1.9.</span> <span class="nav-text">Falcon Atlas Bridge</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Falcon-Model"><span class="nav-number">1.9.1.</span> <span class="nav-text">Falcon Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Falcon-Hook"><span class="nav-number">1.9.2.</span> <span class="nav-text">Falcon Hook</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Limitations-2"><span class="nav-number">1.9.3.</span> <span class="nav-text">Limitations</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Storm-Atlas-Bridge"><span class="nav-number">1.10.</span> <span class="nav-text">Storm Atlas Bridge</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">1.10.1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Storm-Data-Model"><span class="nav-number">1.10.2.</span> <span class="nav-text">Storm Data Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Storm-Atlas-Hook"><span class="nav-number">1.10.3.</span> <span class="nav-text">Storm Atlas Hook</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Limitations-3"><span class="nav-number">1.10.4.</span> <span class="nav-text">Limitations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Installation"><span class="nav-number">1.10.5.</span> <span class="nav-text">Installation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Configuration"><span class="nav-number">1.10.6.</span> <span class="nav-text">Configuration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Storm-Configuration"><span class="nav-number">1.10.6.1.</span> <span class="nav-text">Storm Configuration</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%B9%E9%94%99%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">1.11.</span> <span class="nav-text">容错和高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E4%BB%8B"><span class="nav-number">1.11.1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Atlas-Web-Service"><span class="nav-number">1.11.2.</span> <span class="nav-text">Atlas Web Service</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Setting-up-the-High-Availability-feature-in-Atlas"><span class="nav-number">1.11.2.1.</span> <span class="nav-text">Setting up the High Availability feature in Atlas</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E9%AB%98%E5%8F%AF%E7%94%A8%E6%80%A7%E5%8A%9F%E8%83%BD"><span class="nav-number">1.11.2.2.</span> <span class="nav-text">配置客户端以使用高可用性功能</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%AD%E9%97%B4%E4%BB%A3%E7%90%86"><span class="nav-number">1.11.2.3.</span> <span class="nav-text">使用中间代理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%B4%BB%E5%8A%A8%E5%AE%9E%E4%BE%8B%E7%9A%84%E8%87%AA%E5%8A%A8%E6%A3%80%E6%B5%8B"><span class="nav-number">1.11.2.4.</span> <span class="nav-text">使用活动实例的自动检测</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0-Atlas-%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-number">1.11.2.5.</span> <span class="nav-text">实现 Atlas 高可用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Metadata-Store"><span class="nav-number">1.11.2.6.</span> <span class="nav-text">Metadata Store</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Index-Store"><span class="nav-number">1.11.3.</span> <span class="nav-text">Index Store</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Notification-Server"><span class="nav-number">1.11.4.</span> <span class="nav-text">Notification Server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Known-Issues"><span class="nav-number">1.11.5.</span> <span class="nav-text">Known Issues</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="rczmm"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">rczmm</p>
  <div class="site-description" itemprop="description">你看到的不止如此</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">49</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="http://github.com/rczmm" title="GitHub → http:&#x2F;&#x2F;github.com&#x2F;rczmm" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:3179623450@qq.com" title="E-Mail → mailto:3179623450@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">rczmm</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">307k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">4:39</span>

    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    访问量：<span id="busuanzi_value_site_pv"></span> 次数 |
    访客数：<span id="busuanzi_value_site_uv"></span> 人次
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;"></span>
      <span class="post-meta-item-icon">
        <i class="user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  

  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#valine-comments' ,
        verify: false,
        notify: true,
        appId: 'tbpzEI3JX9x5SMRqI0MYBQHc-9Nh9j0Va',
        appKey: 'UuxnA5liCzoSIlXGGSnWG271',
        placeholder: '都看到这里了，真的不说两句嘛？',
        avatar:'mm',
        guest_info:guest,
        meta:guest,
        pageSize:'10' || 20,
        visitor: true
    });
  </script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
